{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': 'Iris Plants Database\\n====================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris=datasets.load_iris()\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_boundary(x,y,f):\n",
    "  \n",
    "    x_new=x[x[:,f].argsort()]\n",
    "    values_of_classes=y[x[:,f].argsort()]\n",
    "    #print(\"val of class \",values_of_classes)\n",
    "    count_dict_all_classes=np.array([0,0,0]);\n",
    "    for i in values_of_classes:\n",
    "        if i ==0:\n",
    "            count_dict_all_classes[0]+=1;\n",
    "        elif i==1:\n",
    "            count_dict_all_classes[1]+=1;\n",
    "        else:\n",
    "            count_dict_all_classes[2]+=1;\n",
    "    print(\"count_dict_all_classes \",count_dict_all_classes)\n",
    "    gini_node=1-(((count_dict_all_classes[0])/np.sum(count_dict_all_classes))**2)-(((count_dict_all_classes[1])/np.sum(count_dict_all_classes))**2)-(((count_dict_all_classes[2])/np.sum(count_dict_all_classes))**2)\n",
    "    improvement_in_gini=0;\n",
    "    boundary=0;\n",
    "    for i in range(((x.shape[0]))-1):\n",
    "        mid=(x_new[i,f]+x_new[i+1,f])/2;\n",
    "        class0_vals=len(y[x_new[:,f]<=mid]==0);\n",
    "        class1_vals=len(y[x_new[:,f]<=mid]==1);\n",
    "        class2_vals=len(y[x_new[:,f]<=mid]==2);\n",
    "        class01_vals=len(y[x_new[:,f]>mid]==0);\n",
    "        class11_vals=len(y[x_new[:,f]>mid]==1);\n",
    "        class21_vals=len(y[x_new[:,f]>mid]==2);\n",
    "        D=class0_vals+class1_vals+class2_vals+class01_vals+class11_vals+class21_vals;\n",
    "        D1=class0_vals+class1_vals+class2_vals;\n",
    "        D2=class01_vals+class11_vals+class21_vals;\n",
    "        if D1!=0:\n",
    "            p0=class0_vals/D1;\n",
    "            p1=class1_vals/D1;\n",
    "            p2=class2_vals/D1;\n",
    "        else:\n",
    "            p0=0; p1=0;p2=0;\n",
    "        if D2!=0:\n",
    "            p00=class01_vals/D2;\n",
    "            p01=class11_vals/D2;\n",
    "            p02=class21_vals/D2;\n",
    "        else:\n",
    "            p00=0;p01=0;p02=0;\n",
    "        gini_after_split=1-((p0)**2)-((p1)**2)-((p2)**2)-((p00)**2)-((p01)**2)-((p02)**2);\n",
    "        if((gini_node-gini_after_split)>improvement_in_gini):\n",
    "            boundary=mid;\n",
    "            improvement_in_gini=gini_node-gini_after_split;\n",
    "    return boundary;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(x,y,f):\n",
    "    c1=np.count_nonzero(y.flatten()==1);\n",
    "    c2=np.count_nonzero(y.flatten()==2);\n",
    "    c0=y.shape[0]-c1-c2;\n",
    "    if(c0+c1+c2==0):\n",
    "        return 0;\n",
    "    p0=c0/(c0+c1+c2);\n",
    "    p1=c1/(c0+c1+c2);\n",
    "    p2=c2/(c0+c1+c2);\n",
    "    entropy=-((p1)*(math.log10(p1)))-(p2*(math.log10(p2)))-(p0*(math.log10(p0)));\n",
    "    return entropy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain(x,y,f):\n",
    "    boundary=cal_boundary(x,y,f);\n",
    "    GI_before_split=gini_index(x,y,f);\n",
    "    D=x.shape[0];\n",
    "    if D==0:\n",
    "        return 0,boundary;\n",
    "    D1=len(x[x[:,f]<=boundary]);\n",
    "    D2=len(x[x[:,f]>boundary]);\n",
    "    GI_after_split=(D1/D)*(gini_index(x[x[:,f]<=boundary],y[x[:,f]<=boundary],f))+(gini_index(x[x[:,f]>boundary],y[x[:,f]>boundary],f))*(D2/D);\n",
    "    #entropy=entropy(no_of_c1_vals,no_of_c2_vals);\n",
    "    return (GI_before_split-GI_after_split),boundary;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(x,y,sf):\n",
    "    \n",
    "    class1_val=np.count_nonzero(y.flatten()==1);\n",
    "    class2_val=np.count_nonzero(y.flatten()==2);\n",
    "    class0_val=y.shape[0]-class1_val-class2_val;# is len(y[x[:,sf]]==0) correct?\n",
    "    if(class0_val+class1_val+class2_val==0):\n",
    "        return 0;\n",
    "    p0=class0_val/(class0_val+class1_val+class2_val);\n",
    "    p1=class1_val/(class0_val+class1_val+class2_val);\n",
    "    p2=class2_val/(class0_val+class1_val+class2_val);\n",
    "    #print(1-((p0)**2)-((p1)**2)-(p2**2))\n",
    "    return (1-((p0)**2)-((p1)**2)-(p2**2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTreeClassifier_Helper(x,y,feature_indices,level):\n",
    "    \n",
    "    if(len(set(y.flatten()))==1):\n",
    "        \n",
    "        count1=np.count_nonzero(y.flatten()==1);\n",
    "        count2=np.count_nonzero(y.flatten()==2);\n",
    "        count0=y.shape[0]-count1-count2;\n",
    "        print(\"Level \",level)\n",
    "        if(count0!=0):\n",
    "            print(\"Count of 0 = \",count0)\n",
    "        if(count1!=0):\n",
    "            print(\"Count of 1 = \",count1)\n",
    "        if(count2!=0):\n",
    "            print(\"Count of 2 = \",count2)\n",
    "        print(\"Current Entropy is = 0\")\n",
    "        print(\"Reached leaf node\")\n",
    "        \n",
    "        return 0;\n",
    "    elif(len(feature_indices)==0):\n",
    "        return 0;\n",
    "    max_gain=0;\n",
    "    final_selected_feature=0;\n",
    "    fs_boundary=0\n",
    "    i=0\n",
    "    cnt=0\n",
    "    for f in feature_indices:\n",
    "        curr_gain,boundary=gain(x,y,f);\n",
    "        if(max_gain<curr_gain):\n",
    "            max_gain=curr_gain;\n",
    "            final_selected_feature=f;\n",
    "            fs_boundary=boundary;\n",
    "            cnt=i\n",
    "        i=i+1\n",
    "    #printing the count values for the splits\n",
    "    feature_indices=np.delete(feature_indices,cnt)\n",
    "    print(\"Feature indices are \",feature_indices)\n",
    "    GI_node=gini_index(x,y,final_selected_feature);\n",
    "    count1=np.count_nonzero(y.flatten()==1);\n",
    "    count2=np.count_nonzero(y.flatten()==2);\n",
    "    count0=y.shape[0]-count1-count2;\n",
    "    print(\"Level \",level)\n",
    "    print(\"Count of 0 = \",count0)\n",
    "    print(\"Count of 1 = \",count1)\n",
    "    print(\"Count of 2 = \",count2)\n",
    "    print(\"Current Entropy is = \",entropy(x,y,final_selected_feature))\n",
    "    print(\"Splitting on feature X\",final_selected_feature,\" with gini-index \")\n",
    "    print(\"Selected boundary is \",fs_boundary)\n",
    "    print(GI_node)\n",
    "    \n",
    "    decisionTreeClassifier_Helper(x[x[:,final_selected_feature]<=fs_boundary],y[x[:,final_selected_feature]<=fs_boundary],feature_indices,level+1);\n",
    "    decisionTreeClassifier_Helper(x[x[:,final_selected_feature]>fs_boundary],y[x[:,final_selected_feature]>fs_boundary],feature_indices,level+1);\n",
    "    if (cnt>=len(feature_indices)):\n",
    "        feature_indices=np.append(feature_indices,final_selected_feature)\n",
    "    else:\n",
    "        feature_indices=np.insert(feature_indices,final_selected_feature,cnt)\n",
    "    \n",
    "    return 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting to construct decision tree\n",
    "def decisionTreeClassifier(x,y,feature_indices):\n",
    "    #checking base cases\n",
    "    print(\"hi\")\n",
    "    feature_indices_arr=np.array([i for i in range(feature_indices)])\n",
    "    print(feature_indices_arr)\n",
    "    decisionTreeClassifier_Helper(x,y,feature_indices_arr,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    x=iris.data;\n",
    "    y=iris.target;\n",
    "    decisionTreeClassifier(x,y,x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "[0 1 2 3]\n",
      "count_dict_all_classes  [50 50 50]\n",
      "count_dict_all_classes  [50 50 50]\n",
      "count_dict_all_classes  [50 50 50]\n",
      "count_dict_all_classes  [50 50 50]\n",
      "Feature indices are  [0 1 2]\n",
      "Level  0\n",
      "Count of 0 =  50\n",
      "Count of 1 =  50\n",
      "Count of 2 =  50\n",
      "Current Entropy is =  0.4771212547196624\n",
      "Splitting on feature X 3  with gini-index \n",
      "Selected boundary is  0.1\n",
      "0.6666666666666665\n",
      "Level  1\n",
      "Count of 0 =  6\n",
      "Current Entropy is = 0\n",
      "Reached leaf node\n",
      "count_dict_all_classes  [44 50 50]\n",
      "count_dict_all_classes  [44 50 50]\n",
      "count_dict_all_classes  [44 50 50]\n",
      "Feature indices are  [1 2]\n",
      "Level  1\n",
      "Count of 0 =  44\n",
      "Count of 1 =  50\n",
      "Count of 2 =  50\n",
      "Current Entropy is =  0.476356115713346\n",
      "Splitting on feature X 0  with gini-index \n",
      "Selected boundary is  4.4\n",
      "0.6655092592592592\n",
      "Level  2\n",
      "Count of 0 =  3\n",
      "Current Entropy is = 0\n",
      "Reached leaf node\n",
      "count_dict_all_classes  [41 50 50]\n",
      "count_dict_all_classes  [41 50 50]\n",
      "Feature indices are  [1]\n",
      "Level  2\n",
      "Count of 0 =  41\n",
      "Count of 1 =  50\n",
      "Count of 2 =  50\n",
      "Current Entropy is =  0.4753103285482094\n",
      "Splitting on feature X 2  with gini-index \n",
      "Selected boundary is  1.1\n",
      "0.6639505055077713\n",
      "Level  3\n",
      "Count of 0 =  1\n",
      "Current Entropy is = 0\n",
      "Reached leaf node\n",
      "count_dict_all_classes  [40 50 50]\n",
      "Feature indices are  []\n",
      "Level  3\n",
      "Count of 0 =  40\n",
      "Count of 1 =  50\n",
      "Count of 2 =  50\n",
      "Current Entropy is =  0.4748466064873782\n",
      "Splitting on feature X 1  with gini-index \n",
      "Selected boundary is  2.1\n",
      "0.663265306122449\n",
      "Level  4\n",
      "Count of 1 =  1\n",
      "Current Entropy is = 0\n",
      "Reached leaf node\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
